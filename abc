



----------------------------------------
// dslam.cpp

#include "slam.h"

int main (int argc, char** argv) {
    dslam::Slam slam(argc, argv);
    return slam.run();
}


---------------------------------------
// slam.h

#include "layer.h"
#include "builder.h"
#include "communicator.h"
#include "console.h"

pthread_t threadStart(func* func, void* arg) {

	int err;
	pthread_t ntid;
	err = pthread_create(&ntid, NULL, func, arg);
	if (err != 0)
		printf("can't create thread: %s
	", strerror(err));
	return ntid;
}

class Slam {

public:

	Slam(int argc, char** argv) {
		Config::parse(argc, argv);
		pipe = new Pipe();
		player = new Player(Config::videoFile(), pipe);
		graph = new FlowGraph(pipe);
		communictor = new Communicator();
		console = new Console();
	}

	~Slam() {
		delete console;
		delete communicator;
		delete graph;
		delete player;
		delete pipe;
	}

	int run() {
		threadStart(Player::play, player);
		threadStart(Graph::locallyLoop, graph);
		threadStart(Graph::globallyLoop, graph);
		threadStart(Communicator::communictor, communicator);
		return console.start();
	}

private:
	Player player_;
	Graph graph_;
	Communicator communicator_;
	Console console;
	Pipe<Blob*>* pipe;

};

--------------------------------------
// player

namespace dslam:

class Player {

public:
	Player(const char* file, Pipe* pipe) {
		capture = new cv::Capture(file);
		pipe = pipe;
	}
	void play() {
		cv::Mat image = capture.read();
		while(!image.empty()) {
			Blob* blob = new Blob(image);
			pipe->push(blob);
			image = capture.read();
		}
		pipe->push(0);
	}

	static void* play(Player* player) {
	player->play();
	}
private:
	cv::Capture capture;
	Pipe* pipe;

}

----------------------------------------
// pipe

#include <asm/semaphore.h>

namespace dslam:

class Pipe {

public:

	Pipe(int count = 8) {
		capacity_ = count+1;
		iems_ = new malloc(capacity_ * sizof(void*));
		sema_init (&sema_, count);
		push_cur_ = 0;
		pop_cur = 0;
	}

	void push(void* item) {
		down(&sema_);
		items_[push_cur_++] = item;
		push_cur_ %= capacity_;
	}

	~Pipe() {
		free(item_);
	}

	void* pop() {
	up(&sema_);
	void* item = items_[pop_cur_++];
	pop_cur_ %= capacity_;
	return item;
	}

private:

	int capacity_;
	void** items_;
	semaphore sema_;
	int push_cur_;
	int pop_cur_; 
};

----------------------------
// Graph

class Graph() {

public:

	Graph(Pipe* pipe) {
		pipe_ = pipe;
	}

	void locallyLoop() {
		void* image = 0;
		while(image = pipe_->pop()) {
			push(Blob* image);
			localOptimize();
		}
	}

	void globallyLoop() {
		while(true) {
			globalOptimize();
		}
	}

	virtual void push(Blob* image);
	virtual void localOptimize();
	virtual void globalOptimize();

private:
	Pipe* pipe_;


};


----------------------------------
// FlowGraph

class FlowGraph : public Graph {

public:
	
	FlowGraph(Pipe* pipe) : Graph(pipe) {
		localOptimizer = FlowFrameOptimizer();
		globalOptimizer = FlowGraphOptimizer();
	}
	virtual void push(Blob* image) {

		Frame* last = graph->last();
		if (last) {
			Frame frame = new Frame(iamge, last->camera);
			last->addNeighbor(image);
		}
		base::pushFrame(frame);
		
	}
	virtual void localOptimize() {
		localOptimizer->optimizer();
	}
	virtual void globalOptimize() {
		localOptimizer->optimizer();
	}

private:
	Optimizer* localOptimizer;
	Optimizer* globalOptimizer;

};

-------------------------------
// flowframe 

class FlowFrame : public Frame {


protected:

	std::vector<std::pair<Frame*, Flow*>> neighbors;
	
};


------------------------------
// frame

class Frame {

public:
	inline int width() const { return image ? image->shape[3] : 0 }
	inline int height() const { return image ? image->shape[2] : 0 }

protected:
	Blob* image;



};




		threadStart(Builder::build, builder);
https://github.com/gaoqian506/dslam.git

class Builder() {

public:
	Builder(Pipe* pipe) {
		pipe_ = pipe;
		graph_ = new FlowGraph(pipe_);
	}
	void build() {
		threadStart(Graph::locallyOptimize, graph_);
		threadStart(Graph::globallyOptimize, graph_);
		while(true) {
			void* frame = pipe_->pop();
			graph_->addFrame((Frame*)frame);
			
		}
	}


private:
	Pipe* pipe_;
	Graph* graph_;
};




		//dslam::flowGraphCullRedundantFlow(graph);


/**
@brief A 4D int array that descrip the iterate time for a solver optimization.
*/
struct Dimension4 {
	int dimension4[4];
};

/**
@brief A 4D index indicate iterate position when performing a optimizing.
*/
struct Index4 {
	int index[4];
};


/**
@brief Camera parameter suggestion object that descript the increment of camera parameters that will achieve a better consistent respect of optical flow.
*/
struct CameraParameterSuggestionObj {
	/** Suggestion of increment of camera parameters. */
	double suggestion[9];
};

typedef CameraParameterSuggestionObj* CameraParameterSuggestion;

/**
@brief Create a empty camera parameter optimizing suggestion, that the increments are set to zeros.

@return A empty camera parameter suggestion object.
@see CameraParameterSuggestionObj
@note No.
*/
CameraParameterSuggestion createEmptyCameraParameterSuggestion();


/**
@brief Create a empty camera parameter optimizing suggestion from a memory buffer.

@param data The start address of data buffer in memory.
@return A serialized camera parameter suggestion object.
@see createEmptyCameraParameterSuggestion
@note No.
*/
CameraParameterSuggestion createCameraParameterSuggestionFromMemory(double* data);

/**
@brief Update the camera parameters with sugesstion, this will consider the manifold phenomenon.

@param camera Which's parameters will be updated.
@param suggestion The updating suggestion.
@return No.
@see CameraParameterSuggestionObj
@note No.
*/
void incrementCameraParameterWithSuggestion(Camera camera, CameraParameterSuggestion suggestion);

/**
@brief Check whether the optimization is achieved.

@param camera Camera that will be evalated.
@param suggestion Suggestion updating suggestion.
@return true If check passed.
@return false If check failure.
@see CameraParameterSuggestionObj
@note No.
*/
bool cameraParameterOptimizationSatisfied(Camera camera, CameraParameterSuggestion suggestion);


/**
@brief Extract the relative relationship between tow (neighboring) cameras.

@param fromCamera Basis camera.
@param toCamera Target camera the relative information would be extract.
@return Relative camera object.
@see resolveCameraparameterSuggestion().
@note No.
*/
Camera extractRelativeCamera(Camera fromCamera, Camera toCamera);

/**
@brief Release camera parameter suggestion object.

@param suggestion Which object to be released.
@return void.
@see CameraParameterSuggestionObj
@note No.
*/
void releaseCameraParameterSuggestion(CameraParameterSuggestion suggestion);



/**
@brief Optimize camera parameters by the optcal flow constrains, this is to do a non-linear optimizing task, until optimization task is satisfied.

@param camera The optimizing target.
@param neighborCameras The camera vector of neighbors.
@param neighborFlows The optical flow vector of neighbors.
@return NO
@see frameOptimizeCameraParameters() flowGraphLocalOptimize()
@note No.
*/
void resolveCameraParameters(Camera camera, const std::vector<Camera>& neighborCameras, const std::vector<Flow>& neighborFlows);

/**
@brief Optimize camera parameters, by the optcal flow constrains, for one step. Firstly, each neibor give a suggestion, and then, they are fused to a optimized result. If not satisfy terminate condition, then otpimize the parameters again.

@param camera The optimizing target.
@param neighborCameras The camera vector of neighbors.
@param neighborFlows The optical flow vector of neighbors.
@return NO
@see frameOptimizeCameraParameters() flowGraphLocalOptimize()
@note No.
*/
CameraParameterSuggestion resolveCameraparameterSuggestion(Camera camera, const std::vector<Camera>& neighborCameras, const std::vector<Flow>& neighborFlows);

/**
@brief A signle contrain version to optimize camera parameters, by neibor camera and flow. First, extract relative camera between two neighboring cameras, and resovle the suggestion for the relative camera.

@param camera The optimizing target.
@param neighborCamera Neighbor's camera.
@param neighborFlow Neighbor's flow.
@return A camera parameter optimize suggestion object.
@see frameOptimizeCameraParameters(); flowGraphLocalOptimize(); resolveCameraparameterSuggestion().
@note No.
*/
CameraParameterSuggestion resolveCameraparameterSuggestion(Camera camera, const Camera neighborCamera, const Flow neighborFlow);


/**
@brief Resolve camera parameter optimize suggestion via optical flow.

@param camera The optimizing target object, from its initial states.
@param flow The optimizing contrains, to be reconciled by camera adjustment.
@return A camera parameter optimize suggestion object.
@see frameOptimizeCameraParameters(), flowGraphLocalOptimize(), resolveCameraparameterSuggestion(), extractRelativeCamera().
@note No.
*/
CameraParameterSuggestion resolveCameraparameterSuggestion(const Camera camera, const Flow flow);

/**
@brief Fuse several camera parameter optimize suggestions into a one.

@param suggestionVector The vector of camera parameter optimize suggestion, which will be fused.
@return A fused camera parameter optimize suggestion.
@see frameOptimizeCameraParameters(); flowGraphLocalOptimize(); resolveCameraparameterSuggestion().
@note No.
*/
CameraParameterSuggestion fuseCameraParameterSuggestions(const std::vector<CameraParameterSuggestion>& suggestionVector);

/**
@brief Retrieve optimizing result from resolver object.

@param resovler Which from resolver's result will be retrieved.
@return A pointor to memory buffer storing resolver's optimizing result.
@see resolve().
@note No.
*/
double* resolverGetOptimizedResult(Resolver resolver);


double* resolverGetOptimizedResult(Resolver resolver) {
	return NULL;
}



CameraParameterSuggestion createEmptyCameraParameterSuggestion() {
	return new CameraParameterSuggestionObj();
}

CameraParameterSuggestion createCameraParameterSuggestionFromMemory(double* data) {
	return new CameraParameterSuggestionObj();
}

void incrementCameraParameterWithSuggestion(Camera camera, CameraParameterSuggestion suggestion) {



}

bool cameraParameterOptimizationSatisfied(Camera camera, CameraParameterSuggestion suggestion) {
	return true;
}

Camera extractRelativeCamera(Camera fromCamera, Camera toCamera) {
	return createOriginalCamera();
}

void releaseCameraParameterSuggestion(CameraParameterSuggestion suggestion) {
	delete suggestion;
}

void resolveCameraParameters(Camera camera, const std::vector<Camera>& neighborCameras, const std::vector<Flow>& neighborFlows) {

	CameraParameterSuggestion suggestion;
	while (true) {
		suggestion = resolveCameraparameterSuggestion(camera, neighborCameras, neighborFlows);
		incrementCameraParameterWithSuggestion(camera, suggestion);
		if (cameraParameterOptimizationSatisfied(camera, suggestion)) {
			releaseCameraParameterSuggestion(suggestion);
			break;
		}
		releaseCameraParameterSuggestion(suggestion);
	}

}

CameraParameterSuggestion resolveCameraparameterSuggestion(Camera camera, const std::vector<Camera>& neighborCameras, const std::vector<Flow>& neighborFlows) {

	assert(neighborCameras.size() == neighborFlows.size());

	std::vector<Camera>::const_iterator itCamera = neighborCameras.begin();
	std::vector<Flow>::const_iterator itFlow = neighborFlows.begin();

	std::vector<CameraParameterSuggestion> suggestionVector;


	while(itFlow != neighborFlows.end()) {

		CameraParameterSuggestion suggestion = resolveCameraparameterSuggestion(camera, *itCamera, *itFlow);
		suggestionVector.push_back(suggestion);
		itCamera++;
		itFlow++;

	}
	
	return fuseCameraParameterSuggestions(suggestionVector); 
}

CameraParameterSuggestion resolveCameraparameterSuggestion(Camera camera, const Camera neighborCamera, const Flow neighborFlow) {

	Camera relativeCamera = extractRelativeCamera(camera, neighborCamera);
	return resolveCameraparameterSuggestion(relativeCamera, neighborFlow);
}

CameraParameterSuggestion resolveCameraparameterSuggestion(const Camera camera, const Flow flow) {


	Resolver resolver = createEmptyResolver();
	Responder responder = createCameraPrameterResponder(camera, flow);
	resolverSetResponder(responder);

	CameraParameterSuggestion suggestion = createCameraParameterSuggestionFromMemory(
resolverGetOptimizedResult(resolver));

	releaseResolver(resolver);
	releaseResponder(responder);
	
	return suggestion;

}

CameraParameterSuggestion fuseCameraParameterSuggestions(const std::vector<CameraParameterSuggestion>& suggestionVector) {
	return createEmptyCameraParameterSuggestion();
}



	cameraUpdateParameterFromMemory(frame->camera, reolver->result);


std::vector<Camera> frameGetNeighborCameraVector(FlowFrame frame) {
	const std::vector<FlowFrameNeighbor>& neighborVector = frameGetNeighborVector(frame);
	std::vector<Camera> cameraVector;
	for (std::vector<FlowFrameNeighbor>::const_iterator itr = neighborVector.begin(); itr != neighborVector.end(); itr++) {
		cameraVector.push_back((*itr)->frame->camera);
	}
	return cameraVector;
}
std::vector<Flow> frameGetNeighborFlowVector(FlowFrame frame) {
	const std::vector<FlowFrameNeighbor>& neighborVector = frameGetNeighborVector(frame);
	std::vector<Flow> flowVector;
	for (std::vector<FlowFrameNeighbor>::const_iterator itr = neighborVector.begin(); itr != neighborVector.end(); itr++) {
		flowVector.push_back((*itr)->flow);
	}
	return flowVector;
}

std::vector<FlowFrameNeighbor>& frameGetNeighborVector(FlowFrame frame) {
	return frame->neighborVector;
}



	CameraParameterSuggestion suggestion = createCameraParameterSuggestionFromMemory(
resolverGetOptimizedResult(resolver));
	
	return suggestion;
	
	Camera camera = frameGetCamera(frame);
	std::vector<Camera> cameraVector = frameGetNeighborCameraVector(frame);
	std::vector<Flow> flowVector =  frameGetNeighborFlowVector(frame);
	resolveCameraParameters(camera, cameraVector, flowVector);

	
	// for last frame
	// estimate the rotation firstly
	// determine the translation secondly
	// and then update depth
	// as to this, local optimaize completed


void cameraFlowErrorJacobinResolverCallback(void* constrains, void* error, void* yacobin, Indics4 index);




/**
@brief Set error and jacobin callback for a resolver object.

@param resovler Which resolver object will be sed.
@param callback A error and jacobin callback (function pointor.

@return No.
@see No.
@note No.
*/
void resolverSetErrorJacobinCallback(Resolver resolver, ErrorJacobinCallback callback);

/**
@brief Add a constrain to resolver, which will transmit to error-jacobin callback method. The constrain order will in accord with calling sequence.

@param resovler Which resolver object will add constrain to.
@param constrain A constrain element that will transmit to error-jacobin callback method.

@return No.
@see No.
@note No.
*/
void resolverAddConstrain(Resolver resolver, void* constrain);

	
	/** Constrain vector will parsed by specified error-yacobin callback */
	void* constrtains[10];



	/** Callback will be called indexCount times for collecting optimizing infomation. */
	ErrorJacobinCallback ejCallback;

	/** The times will callback will be called. The index passes to callback will interate in this variable. */
	Space4 space;

/**
@brief A definition of error-jacobin callback (function pointor), which will called by a resolver many times to collect optimizing needed infomations.
*/
typedef void (*ErrorJacobinCallback)(void* constrains, void* error, void* yacobin, Indics4 index);



void resolverAddConstrain(Resolver resolver, void* constrain) {
	assert(0);
}

void resolverSetErrorJacobinCallback(Resolver resolver, ErrorJacobinCallback callback) {
	assert(0);

}


void cameraFlowErrorJacobinResolverCallback(void* constrains, void* error, void* yacobin) {

}




void resolve(Resolver resolver) {

	// get target dimensions
	// get source dimensions

	// foreach tDim in target dimensions {
		// err, jacobin
		// foreach sDim in source dimensions {
			// responder->calculateErrorJacobin(tDim, sDim, err, jacobin);
			// accumulate(err jacobin);
		// }
		// set optimizing result at tDim
	// }
/*
	for (int batch = 0; batch < resolver->space[0]; ++batch) {
		for (int channel = 0; channel < resolver->space[1]; ++channel) {
			for (int col = 0; col < resolver->space[2]; ++col) {
				for (int row = 0; row < resolver->sapce[3]; ++row) {
					Indics4 index = { { batch, channel, col, row } };
					ejCallback(resolver->constrains, NULL, NULL, index);
				}
			}
		}
	}
*/
}

void resolverSetErrorJacobinCallback(Resolver resolver, ErrorJacobinCallback callback) {
	assert(0);
	resolver->ejCallback = callback;

}

void resolverAddConstrain(Resolver resolver, void* constrain) {

	assert(0);
	int size = sizeof(resolver->constrains) / sizeof(resolver->constrains[0]);
	int i;
	for (i = 0; i < size; i++) {
		if (resolver->constrains[i] == 0) {
			resolver->constrains[i] = constrain;
			break;
		}
	}
	assert(i < size);
}



Resolver createEmptyResolver(Space4 space) {
	Resolver resolver = new ResolverObj();
	resolver->space = space;
	resolver->ejCallback = NULL;
	memset(resolver->constrains, 0, sizeof(resolver->constrains));
	return resolver;
}
	

/*
	int cols = flowGetColumns(flow);
	int rows = flowGetRows(flow);
	Space4 space = { { 1, 1, cols, rows } };
	Resolver resolver = createEmptyResolver(space);
	resolverAddConstrain(resolver, camera);
	resolverAddConstrain(resolver, flow);
	resolverSetErrorJacobinCallback(resolver,  cameraFlowErrorJacobinResolverCallback);
	resolve(resolver);

	CameraParameterSuggestion suggestion = createCameraParameterSuggestionFromMemory(
resolverGetOptimizedResult(resolver));
	releaseResolver(resolver);
	
	return suggestion;
*/
	return createEmptyCameraParameterSuggestion();

/**
@brief Optimize camera parameters by the optcal flow constrains, this is to do a non-linear optimizing task. Firstly, each neibor give a suggestion, and then, they are fused to a optimized result. If not satisfy terminate condition, then otpimize the parameters again.

@param camera The optimizing target.
@param neighborCameras The camera vector of neighbors.
@param neighborFlows The optical flow vector of neighbors.
@return NO
@see frameOptimizeCameraParameters() flowGraphLocalOptimize()
@note No.
*/
	
	assert(neighborCameras.size() == neighborFlows.size());
	std::vector<Camera>::const_iterator itCamera = neighborCamera.begin();
	std::vector<Flow>::const_iterator itFlow = neighborFlow.begin();


	while(itFlow != neighborFlow.end()) {

		CameraParameterOptimizeSuggestion suggestion = resolveCameraParameterOptimize

		itCamera++;
		itFlow++;

	}

/**
Query all of frame's neighbor cameras.
@param frame Which frame is to query.
@return Vector of neighbors' cameras.
@see CameraObj
@note No.
*/

LIBS+=-lg2o_core
LIBS+=-lg2o_types_sim3
LIBS+=-lg2o_types_data

	if (flow->mat.cols != header.cols ||
		flow->mat.rows != header.rows ||
		flow->mat.type() != header.type ||
		flow->mat.step[1] != header.step ||
		!flow->mat.isContinuous()) {
		flow->mat = cv::Mat(header.rows, header.cols,
			header.type);
	}

void frameAddNeighbor(Frame frame, Frame nFrame, cv::Mat flow) {
	FrameNeighbor neighbor = createFrameNeighbor();
	frameNeighborSetFrame(neighbor, nFrame);
	frameNeighborSetFlow(neighbor, flow);
	frameAddNeighbor(frame, neighbor);

}


		frameAddNeighbor(lastest, frame, flow1);
		frameAddNeighbor(frame, lastest, flow2);
void readFlow(const char* name, cv::Mat& flow) {


	FILE* file = NULL;
	file = fopen(name, "rb");
	if (!file) {
		perror(name);
		return;
	}
	FlowHeader header;
	fread(&header, sizeof(header), 1, file);

	if (flow.cols != header.cols ||
		flow.rows != header.rows ||
		flow.type() != header.type ||
		flow.step[1] != header.step ||
		!flow.isContinuous()) {
		flow = cv::Mat(header.rows, header.cols,
			header.type);
	}

	fread(flow.data, flow.cols*flow.step[1],
		1, file);
	std::cout << "Read flow from file:" << name << std::endl;


	fclose(file);

}

void readFlow(const char* name, Flow flow);

void flowGraphAddFrame(FlowGraph graph, Frame frame);


void frameAddNeighbor(Frame frame, Frame nFrame, Flow flow);

hello NppFtp

//#include <opencv2/core/core.hpp>
//#include <stdio.h>


		
		// read the frame
		// add into frame graph
		// local BA
		// optimize graph


#include <iostream>
#include <opencv2/core/core.hpp>
#include <stdio.h>

cv::Mat read_flow(const char* file_name) {

	FILE* file = NULL;
	file = fopen(file_name, "rb");
	if (!file) {
		perror("Error");
		std::cout << "Unable to open file:" << file_name << std::endl;
		return;
	}
	int size_type[3];

	fread(size_type, sizeof(size_type), 1, file);

	cv::Mat flow = cv::Mat(size_type[0], 
		size_type[1], size_type[2]);
	fread(size_type, sizeof(size_type), 1, file);

	 = { flow.cols, flow.rows, flow.type() };
	fwrite(size_type, sizeof(size_type), 1, file);
	for (int i = 0; i < flow.rows; i++) {
		fwrite(flow.ptr(i), flow.step[0], 1, file);
	}
	fclose(file);

	return cv::Mat();

}


int main(int argc, char** argv) {

	std::cout << "hello local" << std::endl;	
	//while (true) {
	
	char file_name[256];
	for (int i = 0; i < 4; i++) {

		sprintf(file_name, "temp/flow/flow_%d_%d.flw", 
			i, i+1);
		cv::Mat frame = read_flow(file_name);
		
		// read the frame
		// add into frame graph
		// local BA
		// optimize graph

	}
	

}

		std::cout << "Please specify a video file.\n";


#include <stdio.h>							// sprintf
#include <iostream>							// std::cout
#include <opencv2/highgui/highgui.hpp>		// cv::VideoCapture
#include <opencv2/imgproc/imgproc.hpp>		// cv::cvtColor
#include <opencv2/video/video.hpp>			// cv::calcOpticalFlowFarneback
#include <unistd.h> 						// getcwd()


#include "dslam.h"


void save_flow(cv::Mat& flow, int prev_id, int next_id) {


	char file_name[256];
	sprintf(file_name, "temp/flow/flow_%d_%d.flw", prev_id, next_id);

	FILE* file = NULL;
	file = fopen(file_name, "wb");
	if (!file) {
		perror("Error");
		std::cout << "Unable to open file:" << file_name << std::endl;
		return;
	}
	
	int size_type[3] = { flow.cols, flow.rows, flow.type() };
	fwrite(size_type, sizeof(size_type), 1, file);
	for (int i = 0; i < flow.rows; i++) {
		fwrite(flow.ptr(i), flow.step[0], 1, file);
	}
	fclose(file);
	std::cout << "Write flow to file:" << file_name << std::endl;

}


int main(int argc, char** argv) {

	char buffer[1024];
	if (getcwd(buffer, 1024)) {
		std::cout << "cwd:" << buffer << std::endl;
	}
	std::cout << argv[0] << std::endl;
	if (argc < 2) { 
		std::cout << "Please specify a video file.\n";
		return -1;
	}

    cv::VideoCapture capture(argv[1]);
    if(!capture.isOpened()) {
		std::cout << "file not found:" << argv[1] << std::endl;
		return -1;
	}

	cv::Mat prev, next, frame, gray;
	cv::Mat flow;
	int times = 0;
	while(capture.read(frame) && times < 5) {

		cv::cvtColor(frame, gray, CV_BGR2GRAY);
		if (prev.empty()) {
			prev = gray;
		}
		else {
			next = gray;
			cv::calcOpticalFlowFarneback(prev, next, flow, 0.5, 3, 15, 3, 5, 1.2, 0);
			save_flow(flow, times-1, times);
		}
		times++;
	}
	

	std::cout << "hello flow" << std::endl;	
}

/*

	
			//write_ptr = fopen("test.bin","wb");  // w for write, b for binary
			//fwrite(buffer,sizeof(buffer),1,write_ptr); // write 10 bytes from our buffer

			//std::cout << "calcOpticalFlowFarneback(" << times << ")" << std::endl;
			//save(flow);

	for (int i = 0; i < 5; i++) {


    Mat edges;
    namedWindow("edges",1);
    for(;;)
    {
        Mat frame;
        cap >> frame; // get a new frame from camera
        cvtColor(frame, edges, CV_BGR2GRAY);
        GaussianBlur(edges, edges, Size(7,7), 1.5, 1.5);
        Canny(edges, edges, 0, 30, 3);
        imshow("edges", edges);
        if(waitKey(30) >= 0) break;
    }


	open video
	foreach frame {
		calc flow();
		if (step = N) {
			save flow double side;
		}
	}


	const char* file_name = NULL;
	if (argc > 1) {
		file_name = ;
	}
	else {
		file_name = "data/videos/720.mp4";
	}


	char buffer[1024];
	if (getcwd(buffer, 1024)) {
		std::cout << "cwd:" << buffer << std::endl;
	}

*/







flow:
	utils/flow data/videos/720.mp4



\begin{subfigure}{0.4\textwidth}
	\includegraphics[width=0.4\linewidth]{docs/soba/mr-flow1.jpg}
	\caption{Illustration1 of MR-FLOW}
\end{subfigure}

\begin{subfigure}{0.4\textwidth}
	\includegraphics[width=0.4\linewidth]{docs/soba/mr-flow1.jpg}
	\caption{Illustration1 of MR-FLOW}
\end{subfigure}



\begin{subfigure}{0.32\textwidth}
	\includegraphics[width=\linewidth]{docs/soba/header_scene_flow.jpg}
	\caption{Illustration2 of MR-FLOW}
\end{subfigure}

\begin{subfigure}{0.32\textwidth}
	\includegraphics[width=\linewidth]{docs/soba/header_scene_flow.jpg}
	\caption{Illustration2 of MR-FLOW}
\end{subfigure}


\minipage{0.32\textwidth}
	\includegraphics[width=\linewidth]{docs/soba/mr-flow1.jpg}
	\caption{Illustration1 of MR-FLOW}
\endminipage \hfill

\minipage{0.32\textwidth}
	\includegraphics[width=\linewidth]{docs/soba/header_scene_flow.jpg}
	\caption{Illustration2 of MR-FLOW}
\endminipage \hfill

\minipage{0.32\textwidth}
	\includegraphics[width=\linewidth]{docs/soba/header_scene_flow.jpg}
	\caption{Illustration2 of MR-FLOW}
\endminipage

\begin{displaymath}

E=\sum (x'Fx)^2

\end{displaymath}


@inproceedings{Furukawa2008Accurate,
  title={Accurate camera calibration from multi-view stereo and bundle adjustment},
  author={Furukawa, Yasutaka and Ponce, Jean},
  booktitle={Computer Vision and Pattern Recognition, 2008. CVPR 2008. IEEE Conference on},
  pages={257-268},
  year={2008},
}


\cite{Bai2016Exploiting}\cite{Oisel2001Epipolar}\cite{Valgaerts2008A}\cite{Wedel2009Structure}\cite{Yuan2007Detecting}. The top monocular optical flow method on the KITTI-2012 benchmark estimates the fundamental matrix and computes flow along the epipolar lines [40]. This approach is limited to fully rigid scenes. Wedel et al. [39] compute the fundamental matrix and regularize optical flow to lie along the epipolar lines. If they detect independent motion, they revert to standard optical flow for the entire frame. 



@article{Heeger1992Subspace,
  title={Subspace methods for recovering rigid motion I: Algorithm and implementation},
  author={Heeger, David J. and Jepson, Allan D.},
  journal={International Journal of Computer Vision},
  volume={7},
  number={2},
  pages={95-117},
  year={1992},
}



@article{Horn1988Direct,
  title={Direct methods for recovering motion},
  author={Horn, Berthold K. P. and Weldon, E. J.},
  journal={International Journal of Computer Vision},
  volume={2},
  number={1},
  pages={51-76},
  year={1988},
}


@inproceedings{Bai2016Exploiting,
  title={Exploiting Semantic Information and Deep Matching for Optical Flow},
  author={Bai, Min and Luo, Wenjie and Kundu, Kaustav and Urtasun, Raquel},
  booktitle={European Conference on Computer Vision},
  pages={154-170},
  year={2016},
}

@article{Oisel2001Epipolar,
  title={Epipolar constrained motion estimation for reconstruction from video sequences},
  author={Oisel, Lionel and Memin, Etienne and Morin, Luce and Labit, Claude},
  year={2001},
}

@inproceedings{Valgaerts2008A,
  title={A Variational Model for the Joint Recovery of the Fundamental Matrix and the Optical Flow},
  author={Valgaerts, Levi and Bruhn, AndrÃ©s and Weickert, Joachim},
  booktitle={Dagm Symposium on Pattern Recognition},
  pages={314-324},
  year={2008},
}

@inproceedings{Wedel2009Structure,
  title={Structure- and motion-adaptive regularization for high accuracy optic flow},
  author={Wedel, Andreas and Cremers, Daniel and Pock, Thomas and Bischof, Horst},
  booktitle={IEEE  International Conference on Computer Vision},
  pages={1663-1668},
  year={2009},
}


@article{Yuan2007Detecting,
  title={Detecting Motion Regions in the Presence of a Strong Parallax from a Moving Camera by Multiview Geometric Constraints},
  author={Yuan, Chang and Medioni, Gerard and Kang, Jinman and Cohen, Isaac},
  journal={IEEE Transactions on Pattern Analysis & Machine Intelligence},
  volume={29},
  number={9},
  pages={1627-1641},
  year={2007},
}





	pdftotext $@

import os


def main() :
	str = os.popen("find -name *.tex").read()
	texs = str.split('\n')
	for tex_name in texs : 
		if not tex_name : 
			continue
		pdf_name = os.path.splitext(tex_name)[0]+".pdf"
		bib_name = os.path.splitext(tex_name)[0]+".bib"
		if (os.path.isfile(bib_name)) :
			#if (os.path.isfile(pdf_name) and os.path.getmtime(pdf_name) > os.path.getmtime(tex_name) and os.path.getmtime(pdf_name) > os.path.getmtime(bib_name)) :
				#continue
			print("xelatex -output-directory=%s %s" % (os.path.dirname(tex_name), tex_name))
			print("--------1: %s %s--------" % ("xelatex", tex_name))
			os.system("xelatex -output-directory=%s %s" % (os.path.dirname(tex_name), tex_name))
			aux_name = os.path.splitext(tex_name)[0]+".aux"
			print("--------2: %s %s--------" % ("bibtex", aux_name))
			os.system("bibtex %s" % aux_name)
			print("--------3: %s %s--------" % ("xelatex", tex_name))
			os.system("xelatex -output-directory=%s %s" % (os.path.dirname(tex_name), tex_name))
			print("--------4: %s %s--------" % ("xelatex", tex_name))
			os.system("xelatex -output-directory=%s %s" % (os.path.dirname(tex_name), tex_name))
		else :
			#if (os.path.isfile(pdf_name) and os.path.getmtime(pdf_name) > os.path.getmtime(tex_name)) :
				#continue
			print("--------straint: %s %s--------" % ("xelatex", tex_name))
			os.system("xelatex -output-directory=%s %s" % (os.path.dirname(tex_name), tex_name))
	'''
	find all tex file
	if associated with bib file	
		if (pdf is empy or old than tex or bib)
			compile bbl and pdf
	else if (pdf is empty or old than tex) 
		compile pdf
	endif
	'''

if __name__ == "__main__" :
	main()


NAME = ddslam

TEXS=$(wildcard docs/*.tex)
PDFS=$(TEXS:%.tex=%.pdf)

#SRCS=$(wildcard  src/*.cpp)
#OBJS=$(SRCS:%.cpp=%.o)
UTL_SRCS=$(wildcard  utils/*.cpp)
UTLS=$(UTL_SRCS:%.cpp=%.utl)


LIBS = -lopencv_highgui -lopencv_core -lopencv_imgproc -lopencv_video



all : pdfs utls 

pdfs : $(PDFS)

utls : $(UTLS)

%.pdf : %.tex %.bib
	@echo 0
	xelatex -output-directory=docs $<
	@echo 1 
	bibtex $*.aux
	@echo 2
	xelatex -output-directory=docs $<
	@echo 3
	xelatex -output-directory=docs $<

%.bib :
	touch $@

%.utl : %.cpp 
	g++ -g $< $(LIBS) -o $@

clean:
	find -name "*~" -type f -delete
	find -name "*.flw" -type f -delete
	find -name "*.aux" -type f -delete
	find -name "*.log" -type f -delete
	find -name "*.bbl" -type f -delete
	find -name "*.blg" -type f -delete
	find -name "*.pdf" -type f -delete
	find -name "*.utl" -type f -delete

debug_flow:
	gdb utils/flow.utl

flow:
	utils/flow data/videos/720.mp4

echo:
	@echo LIBS:
	@echo $(LIBS)
	@echo UTILS:
	@echo $(UTILS)
	@echo UTLI_SRCS:
	@echo $(UTLI_SRCS)
	@echo TOOL_OBJS:
	@echo $(TOOL_OBJS)



NAME = ddslam

TEXS=$(wildcard docs/*.tex)
PDFS=$(TEXS:%.tex=%.pdf)
#LOGS=$(TEXS:%.tex=%.log)
#AUXS=$(TEXS:%.tex=%.aux)
BIBS=$(TEXS:%.tex=%.bib)
#BBLS=$(TEXS:%.tex=%.bbl)
#BLGS=$(TEXS:%.tex=%.blg)

SRCS=$(wildcard  src/*.cpp)
OBJS=$(SRCS:%.cpp=%.o)
UTLI_SRCS=$(wildcard  utils/*.cpp)
UTILS=$(UTLI_SRCS:%.cpp=%.utl)
BIB=

LIBS = -lopencv_highgui -lopencv_core -lopencv_imgproc -lopencv_video

all : pdfs utils 

pdfs : $(PDFS)

utils : $(UTILS)


%.pdf : %.tex %.bib
	xelatex -output-directory=docs $<

%.bib :

%.utl : %.cpp 
	g++ -g $< $(LIBS) -o $@


	@g++ -g $< $(LIBS) -o $@

clean:
	@echo Remove temporary files
	@rm -f $(PDFS) $(LOGS) $(AUXS) $(UTILS) $(BBLS) $(BLGS)
	@find -name "*~" -type f -delete
	@find -name "*.flw" -type f -delete
	@find -name "*.aux" -type f -delete
	@find -name "*.log" -type f -delete
	@find -name "*.bbl" -type f -delete
	@find -name "*.blg" -type f -delete

debug_flow:
	gdb utils/flow

flow:
	utils/flow data/videos/720.mp4

echo:
	@echo LIBS:
	@echo $(LIBS)
	@echo UTILS:
	@echo $(UTILS)
	@echo UTLI_SRCS:
	@echo $(UTLI_SRCS)
	@echo TOOL_OBJS:
	@echo $(TOOL_OBJS)


other:
	@echo $< $(wildcard $(BIB))
	@echo ----------------------------
	aaabbbccc aaaabbbccc
	@echo ---------------------------------
	xelatex -output-directory=docs $<
	@echo ---------------------------------
	bibtex  $(basename $<).aux
	@echo ---------------------------------
	xelatex -output-directory=docs $<
	@echo ---------------------------------
	xelatex -output-directory=docs $<

	$(eval BIB=$(join $(basename $<),.bib)) 
	@echo $(BIB)
	$(eval FIND=$(wildcard $(join $(basename $<),.bib)) 
	@echo $(FIND)
	echo $(word 1, $<)
	echo $(word 2, $<)
$(BIBS) :

$(UTILS) : % : %.cpp 
$(PDFS) : %.pdf : %.tex %.bib 
	@echo $^
	@echo $(wildcard $(word 2, $^))
	$(eval BIB=$(word 2, $^))
	$(eval FIND=$(wildcard $(BIB)))
	@echo BIB=$(BIB)
	@echo FIND=$(FIND)
ifeq ($(BIB), $(FIND))
	echo aaa
else
	echo bbb
endif	

$(BIBS) :

$(UTILS) : % : %.cpp 
	@echo g++ -g $< -o $@
ifeq ("$(BIB)","$(FIND)")
	@echo yes!
else
	@echo no!
endif
ifeq ($(word 2, $<), )
	echo no bib
else
	echo has bib
endif

#$(error err)
#$(BBLS) : %.bbl : %.tex %.bib
#@echo $< $@ $(word 2,$^)
#@echo -------------------
#$(UTILS) : $(TOOL_OBJS) 
#	g++ -g $< -o $@

#$(UTILS_OBJS) : %.o : %.cpp
#	g++ -c -g $< -o $@
#TOOL_OBJS=$(UTLI_SRCS:%.cpp=%.o)
#rm -f *~ docs/*~ srcs/*~ utils/*~ html/*~
#UTILS = $(basename $(UTLI_SRCS))
#	@echo NAMES:
#	@echo $(NAMES)

# 
#TARGETS = $(NAME).pdf $(NAME).dvi
#
# $(TARGETS) : $(NAME).tex
#	latex $(NAME).tex
#	
#
#dvi:
#	xdvi $(NAME).dvi
#rm $(TARGETS) $(NAME).aux $(NAME).log

\subsection{Web Page}

combox: video1, video2...\\
button: flow, coarse, refine
\iffalse
\section{Detail Design}

\subsection{Work.php}
flow.cpp::main()\\
\indent OpenVideo()\\
\indent ForEachFrame()
\indent CalcFlow()

\subsection{Work.php::ClacFlow}
Work.php::CalcFlow()\\
\indent output is exec(../utils/flow video name)\\
\indent echo output


\subsection{CPP::flow}
CPP::flow()\\
\indent aaa

\fi



